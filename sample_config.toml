default_model = "bodega-current"
default_thinking = true

[models.bodega-current]
provider = "bodega"
model = "current"
max_context_size = 32768
capabilities = ["thinking"]

[models.bodega-raptor]
provider = "bodega"
model = "srswti/bodega-raptor-8b-mxfp4"
max_context_size = 32768
capabilities = ["thinking"]

[models.bodega-raptor-small]
provider = "bodega"
model = "srswti/bodega-raptor-90m"
max_context_size = 32768
capabilities = ["thinking"]

[models.bodega-blackbird]
provider = "bodega"
model = "srswti/blackbird-she-doesnt-refuse-21b"
max_context_size = 128000
capabilities = ["thinking"]

[models.kimi-k2-thinking]
provider = "openrouter"
model = "moonshotai/kimi-k2-thinking"
max_context_size = 262144
capabilities = ["thinking"]

[models.nemotron-nano]
provider = "openrouter"
model = "nvidia/nemotron-3-nano-30b-a3b"
max_context_size = 32000

[models.glm-4-flash]
provider = "openrouter"
model = "z-ai/glm-4.7-flash:nitro"
max_context_size = 128000

[models.deepseek-r1]
provider = "openrouter"
model = "deepseek/deepseek-r1"
max_context_size = 64000
capabilities = ["thinking", "always_thinking"]

[models.deepseek-r1-distill-qwen]
provider = "openrouter"
model = "deepseek/deepseek-r1-distill-qwen-32b"
max_context_size = 64000
capabilities = ["thinking"]

[models.qwen-coder-32b]
provider = "openrouter"
model = "qwen/qwen-2.5-coder-32b-instruct"
max_context_size = 32000

[models.codestral]
provider = "openrouter"
model = "mistralai/codestral-latest"
max_context_size = 32000

[models.claude-sonnet]
provider = "anthropic"
model = "claude-3-5-sonnet-latest"
max_context_size = 200000
capabilities = ["thinking", "image_in"]

[models.claude-4-5-sonnet]
provider = "anthropic"
model = "claude-sonnet-4-5-20250929"
max_context_size = 200000
capabilities = ["thinking", "image_in"]


[models.gpt-nano]
provider = "openai"
model = "gpt-5-nano-2025-08-07"
max_context_size = 200000
capabilities = ["thinking", "always_thinking"]

[models.gpt-5-2]
provider = "openai"
model = "gpt-5.2-2025-12-11"
max_context_size = 200000
capabilities = ["thinking", "always_thinking"]

[providers.openrouter]
type = "openai_legacy"
base_url = "https://openrouter.ai/api/v1"
api_key = "sk-or-v1-"
reasoning_key = "reasoning"

[providers.openrouter.custom_headers]
HTTP-Referer = "https://github.com/SRSWTI/axe"
X-Title = "axe"

[providers.openai]
type = "openai_responses"
base_url = "https://api.openai.com/v1"
api_key = "sk-proj-...."
reasoning_key = "reasoning"

[providers.anthropic]
type = "anthropic"
base_url = "https://api.anthropic.com/v1"
api_key = "sk-ant-api...."
reasoning_key = "reasoning"

[providers.bodega]
type = "bodega"
base_url = "http://localhost:44468"
api_key = ""

[loop_control]
max_steps_per_turn = 100
max_retries_per_step = 3
max_ralph_iterations = 0
reserved_context_size = 50000

[services]

[mcp.client]
tool_call_timeout_ms = 300000  # 5 minutes
